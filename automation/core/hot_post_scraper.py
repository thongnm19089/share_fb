import json
import logging
import time
import re
from datetime import timedelta
from django.utils import timezone
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout

logger = logging.getLogger(__name__)


class HotPostScraper:
    def __init__(self, headless=True):
        self.headless = headless

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Cookie helpers
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_cookies(self, context, cookies_json_str):
        if not cookies_json_str:
            return
        try:
            cookies = json.loads(cookies_json_str)
            if isinstance(cookies, dict):
                cookies = [cookies]
            if not isinstance(cookies, list):
                logger.error(f"Expected list of cookies, got {type(cookies)}")
                return
            valid = []
            for c in cookies:
                if isinstance(c, dict) and 'name' in c and 'value' in c:
                    c.setdefault('domain', '.facebook.com')
                    c.setdefault('path', '/')
                    valid.append(c)
            if valid:
                context.add_cookies(valid)
                logger.info(f"Loaded {len(valid)} cookies.")
            else:
                logger.warning("No valid cookies found.")
        except Exception as e:
            logger.error(f"Cookie error: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Number parser  (1,2K â†’ 1200 | 64 â†’ 64 | 1.200 â†’ 1200)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _parse_number(self, text):
        if not text:
            return 0
        s = str(text).strip()

        # Dáº¥u pháº©y dáº¡ng tháº­p phÃ¢n (1,2K) â†’ cháº¥m
        s = re.sub(r',(?=\d{1,2}\s*[kKmMtT])', '.', s)
        # Dáº¥u cháº¥m phÃ¢n hÃ ng nghÃ¬n (1.200) â†’ xÃ³a (chá»‰ khi KHÃ”NG theo sau bá»Ÿi K/M)
        s = re.sub(r'\.(?=\d{3}(?!\d)(?!\s*[kKmMtT]))', '', s)
        # CÃ²n láº¡i dáº¥u pháº©y lÃ  phÃ¢n hÃ ng nghÃ¬n
        s = s.replace(',', '')

        m = re.search(r'([\d.]+)\s*(k|m|b|tr|triá»‡u|nghÃ¬n)?', s, re.IGNORECASE)
        if not m:
            return 0
        try:
            val = float(m.group(1).rstrip('.'))
            unit = (m.group(2) or '').lower()
            if unit in ('k', 'nghÃ¬n'):
                val *= 1_000
            elif unit in ('m', 'tr', 'triá»‡u'):
                val *= 1_000_000
            elif unit == 'b':
                val *= 1_000_000_000
            return int(val)
        except Exception:
            return 0

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Time parser  ("15 giá»" â†’ datetime | "Vá»«a xong" â†’ now | old â†’ None)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _parse_time_string(self, raw):
        """
        Returns (datetime, within_24h: bool).
        within_24h=True  â†’ bÃ i trong 24h trÆ°á»›c
        within_24h=False â†’ bÃ i cÅ© hÆ¡n hoáº·c khÃ´ng parse Ä‘Æ°á»£c
        """
        now = timezone.now()
        s = (raw or '').lower().strip()
        if not s:
            return None, False

        # Vá»«a xong / just now
        if any(x in s for x in ['vá»«a xong', 'just now']):
            return now - timedelta(seconds=30), True

        # X giÃ¢y
        m = re.search(r'(\d+)\s*(giÃ¢y|sec)', s)
        if m:
            return now - timedelta(seconds=int(m.group(1))), True

        # X phÃºt / X mins
        m = re.search(r'(\d+)\s*(phÃºt|min)', s)
        if m:
            return now - timedelta(minutes=int(m.group(1))), True

        # X giá» / X hrs / Xh (Facebook EN thÆ°á»ng viáº¿t "15h" hoáº·c "15 hrs")
        m = re.search(r'(\d+)\s*(giá»|gr|hrs?|h)\b', s)
        if m:
            hours = int(m.group(1))
            if hours <= 24:
                return now - timedelta(hours=hours), True
            return None, False

        # HÃ´m qua / yesterday (cÃ³ thá»ƒ kÃ¨m giá»)
        if 'hÃ´m qua' in s or 'yesterday' in s:
            t = re.search(r'(\d{1,2}):(\d{2})', s)
            if t:
                hr, mn = int(t.group(1)), int(t.group(2))
                candidate = (now - timedelta(days=1)).replace(
                    hour=hr, minute=mn, second=0, microsecond=0)
                if (now - candidate).total_seconds() <= 86400:
                    return candidate, True
            return now - timedelta(days=1), True

        # Giá» hÃ´m nay "10:30"
        m = re.match(r'^(\d{1,2}):(\d{2})$', s)
        if m:
            hr, mn = int(m.group(1)), int(m.group(2))
            candidate = now.replace(hour=hr, minute=mn, second=0, microsecond=0)
            if candidate > now:
                candidate -= timedelta(days=1)
            if (now - candidate).total_seconds() <= 86400:
                return candidate, True
            return None, False

        # Unix timestamp (data-utime attribute)
        m = re.match(r'^\d{10}$', s)
        if m:
            from datetime import datetime
            import pytz
            dt = datetime.fromtimestamp(int(s), tz=pytz.UTC)
            if (now - dt).total_seconds() <= 86400:
                return dt, True
            return dt, False

        return None, False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 1: Collect post links from the page feed
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _collect_post_links(self, page, progress_callback=None):
        """
        Scroll qua feed, thu tháº­p cÃ¡c link bÃ i viáº¿t POST trong 24h.
        Tráº£ vá» list[str] â€“ danh sÃ¡ch URL bÃ i viáº¿t khÃ´ng trÃ¹ng.
        """
        post_links = {}   # url â†’ posted_at  (hoáº·c None náº¿u chÆ°a parse Ä‘Æ°á»£c time)
        seen = set()

        MAX_SCROLLS = 40
        SCROLL_STEP  = 2500
        SCROLL_PAUSE = 2.5
        MAX_OLD_STREAK = 4   # sá»‘ bÃ i cÅ© liÃªn tiáº¿p thÃ¬ dá»«ng
        no_new_count = 0
        last_count = 0
        old_streak = 0

        # Selector link bÃ i viáº¿t
        LINK_SELECTOR = (
            "a[href*='/posts/'], a[href*='/videos/'], "
            "a[href*='/photos/'], a[href*='fbid='], a[href*='/permalink/']"
        )

        def _normalize(url):
            if not url:
                return url
            if url.startswith('/'):
                url = 'https://www.facebook.com' + url
            if '?' in url and 'fbid=' not in url:
                url = url.split('?')[0]
            return url.rstrip('/')

        def _scan_links():
            """Thu tháº­p link & time tá»« DOM hiá»‡n táº¡i."""
            nonlocal old_streak
            new_found = 0
            try:
                links = page.locator(LINK_SELECTOR).all()
                for link_el in links:
                    try:
                        href = link_el.get_attribute('href') or ''
                        url = _normalize(href)
                        if not url or url in seen:
                            continue
                        seen.add(url)

                        # Thá»­ parse time tá»« text ngáº¯n káº¿ link
                        text = link_el.inner_text().strip()
                        posted_at = None
                        if text and len(text) < 20:
                            dt, ok = self._parse_time_string(text)
                            if ok:
                                posted_at = dt
                                old_streak = 0
                            elif dt is not None:
                                # BÃ i cÅ© hÆ¡n 24h â†’ tÄƒng streak
                                old_streak += 1
                                continue  # bá» qua bÃ i cÅ©
                        # Náº¿u khÃ´ng láº¥y Ä‘Æ°á»£c time tá»« text, váº«n thu tháº­p URL Ä‘á»ƒ click sau
                        post_links[url] = posted_at
                        new_found += 1
                    except Exception:
                        pass
            except Exception as e:
                logger.debug(f"_scan_links error: {e}")
            return new_found

        for i in range(MAX_SCROLLS):
            page.mouse.wheel(0, SCROLL_STEP)
            time.sleep(SCROLL_PAUSE)

            if progress_callback:
                progress_callback(min(45, int((i / MAX_SCROLLS) * 45)))

            new = _scan_links()
            current_count = len(post_links)

            if current_count == last_count:
                no_new_count += 1
                if no_new_count >= 3:
                    logger.info("No new links after 3 scrolls, stopping.")
                    break
            else:
                no_new_count = 0
                last_count = current_count

            if old_streak >= MAX_OLD_STREAK:
                logger.info(f"Hit {old_streak} old posts in a row, stopping scroll.")
                break

            logger.debug(f"Scroll {i+1}: total links={current_count}, old_streak={old_streak}")

        logger.info(f"Collected {len(post_links)} post links.")
        return list(post_links.keys())

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 2: Click tá»«ng link â†’ má»Ÿ popup â†’ parse chi tiáº¿t
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _parse_popup(self, page):
        """
        Sau khi popup bÃ i viáº¿t má»Ÿ, Ä‘á»c thÃ´ng tin tá»« popup.
        Tráº£ vá» dict hoáº·c None.

        Cáº¥u trÃºc popup dá»±a trÃªn áº£nh ngÆ°á»i dÃ¹ng gá»­i:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  [Avatar] TÃªn trang  Â·  15 giá»  Â·  ğŸŒ   â”‚
        â”‚  Caption text...                         â”‚
        â”‚  [áº¢nh/Video]                             â”‚
        â”‚  ğŸ˜â¤ï¸ 1,2K          64 bÃ¬nh luáº­n  130... â”‚
        â”‚  [ThÃ­ch] [BÃ¬nh luáº­n] [Chia sáº»]          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        # Chá» popup load
        POPUP_SELECTOR = "div[role='dialog'], div[data-pagelet='MediaViewerPhoto']"
        try:
            page.wait_for_selector(POPUP_SELECTOR, timeout=8000)
        except PlaywrightTimeout:
            # Thá»­ fallback: cÃ³ thá»ƒ navigate sang trang má»›i
            logger.debug("Dialog not found, reading current page directly.")

        # Láº¥y container chÃ­nh cá»§a popup
        dialog = page.locator("div[role='dialog']")
        if dialog.count() == 0:
            # KhÃ´ng cÃ³ dialog, Ä‘á»c tá»« toÃ n trang (Ä‘Ã£ navigate)
            dialog = page.locator("body")

        posted_at = None
        time_raw = ""
        caption = ""
        likes = 0
        comments = 0
        shares = 0

        # â”€â”€ Thá»i gian â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Thá»­ data-utime (chÃ­nh xÃ¡c nháº¥t)
        try:
            utime_el = dialog.locator("abbr[data-utime]").first
            if utime_el.count() > 0:
                utime = utime_el.get_attribute("data-utime")
                time_raw = utime  # sáº½ parse bÃªn dÆ°á»›i
                if utime:
                    from datetime import datetime
                    import pytz
                    dt = datetime.fromtimestamp(int(utime), tz=pytz.UTC)
                    posted_at = dt
        except Exception:
            pass

        # Fallback: tÃ¬m text dáº¡ng "15 giá» Â·" gáº§n tÃªn trang
        if not posted_at:
            try:
                time_candidates = dialog.locator("a[role='link'] span, span[role='tooltip'], abbr").all()
                for el in time_candidates:
                    txt = el.inner_text().strip()
                    if txt and len(txt) < 25:
                        dt, ok = self._parse_time_string(txt)
                        if ok and dt:
                            posted_at = dt
                            time_raw = txt
                            break
            except Exception:
                pass

        # Fallback cuá»‘i: quÃ©t inner_text tÃ¬m pattern "X giá»" hoáº·c "X phÃºt"
        if not posted_at:
            try:
                full_text = dialog.inner_text()
                for m in re.finditer(
                    r'(\d+)\s*(phÃºt|giá»|mins?|hrs?|h)\b', full_text, re.IGNORECASE
                ):
                    dt, ok = self._parse_time_string(m.group(0))
                    if ok and dt:
                        posted_at = dt
                        time_raw = m.group(0)
                        break
            except Exception:
                pass

        # â”€â”€ Caption â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            # Thá»­ selector chuáº©n
            msg_el = dialog.locator("div[data-ad-preview='message']")
            if msg_el.count() > 0:
                caption = msg_el.first.inner_text().strip()
        except Exception:
            pass

        if not caption:
            try:
                # div[dir='auto'] dÃ i nháº¥t
                nodes = dialog.locator("div[dir='auto'], span[dir='auto']").all()
                skip_kw = ['bÃ¬nh luáº­n', 'chia sáº»', 'thÃ­ch', 'comment', 'share', 'like', 'reactions']
                best = ""
                for node in nodes:
                    t = node.inner_text().strip()
                    if (len(t) > len(best)
                            and not any(kw in t.lower() for kw in skip_kw)
                            and len(t) > 5):
                        best = t
                caption = best
            except Exception:
                pass

        caption = caption[:500] + ('...' if len(caption) > 500 else '')

        # â”€â”€ Likes / Reactions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Popup Facebook hiá»ƒn thá»‹ count reactions dáº¡ng:
        #  <span aria-label="1,2K ngÆ°á»i bÃ y tá» cáº£m xÃºc">  hoáº·c text gá»n "1,2K"
        try:
            labeled = dialog.locator("[aria-label]").all()
            for el in labeled:
                label = (el.get_attribute("aria-label") or "").lower()
                if any(x in label for x in ['cáº£m xÃºc', 'react', 'lÆ°á»£t thÃ­ch', 'likes', 'ngÆ°á»i thÃ­ch']):
                    n = self._parse_number(label)
                    if n > likes:
                        likes = n
        except Exception:
            pass

        # Fallback: sá»‘ nhá» cáº¡nh emoji reactions
        if likes == 0:
            try:
                # TÃ¬m span chá»©a sá»‘ ngay sau khu vá»±c emoji reactions
                # Facebook thÆ°á»ng dÃ¹ng: <span>1,2K</span> hoáº·c aria-label trá»±c tiáº¿p
                reaction_spans = dialog.locator(
                    "span[class*='reactions'], div[class*='reactions'], "
                    "span[aria-label*='cáº£m xÃºc'], span[aria-label*='like'], "
                    "div[aria-label*='lÆ°á»£t thÃ­ch']"
                ).all()
                for sp in reaction_spans:
                    txt = sp.text_content() or ""
                    n = self._parse_number(txt)
                    if n > likes:
                        likes = n

                # Äá»c text thÃ´: tÃ¬m sá»‘ ngay trÆ°á»›c "bÃ¬nh luáº­n"
                if likes == 0:
                    raw_text = dialog.inner_text()
                    # Pattern: "ğŸ˜â¤ï¸ 1,2K    64 bÃ¬nh luáº­n   130 lÆ°á»£t chia sáº»"
                    m = re.search(
                        r'([\d.,]+[kKmM]?)\s+[\d.,]+[kKmM]?\s+bÃ¬nh luáº­n', raw_text
                    )
                    if m:
                        likes = self._parse_number(m.group(1))
            except Exception:
                pass

        # â”€â”€ Comments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            # aria-label
            labeled = dialog.locator("[aria-label]").all()
            for el in labeled:
                label = (el.get_attribute("aria-label") or "").lower()
                if 'bÃ¬nh luáº­n' in label or 'comment' in label:
                    if label not in ['bÃ¬nh luáº­n', 'viáº¿t bÃ¬nh luáº­n', 'comment', 'write a comment']:
                        n = self._parse_number(label)
                        if n > comments:
                            comments = n
        except Exception:
            pass

        if comments == 0:
            try:
                raw_text = dialog.inner_text()
                m = re.search(r'([\d.,]+[kKmM]?)\s*bÃ¬nh luáº­n', raw_text, re.IGNORECASE)
                if m:
                    comments = self._parse_number(m.group(1))
                else:
                    m = re.search(r'([\d.,]+[kKmM]?)\s*comment', raw_text, re.IGNORECASE)
                    if m:
                        comments = self._parse_number(m.group(1))
            except Exception:
                pass

        # â”€â”€ Shares â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            labeled = dialog.locator("[aria-label]").all()
            for el in labeled:
                label = (el.get_attribute("aria-label") or "").lower()
                if ('chia sáº»' in label or 'share' in label):
                    if label not in ['chia sáº»', 'share', 'chia sáº» bÃ i viáº¿t', 'share post']:
                        n = self._parse_number(label)
                        if n > shares:
                            shares = n
        except Exception:
            pass

        if shares == 0:
            try:
                raw_text = dialog.inner_text()
                for pattern in [
                    r'([\d.,]+[kKmM]?)\s*lÆ°á»£t chia sáº»',
                    r'([\d.,]+[kKmM]?)\s*chia sáº»',
                    r'([\d.,]+[kKmM]?)\s*share',
                ]:
                    m = re.search(pattern, raw_text, re.IGNORECASE)
                    if m:
                        shares = self._parse_number(m.group(1))
                        if shares > 0:
                            break
            except Exception:
                pass

        if not posted_at:
            return None

        return {
            'posted_at': posted_at,
            'time_raw': time_raw,
            'caption': caption,
            'likes': likes,
            'comments': comments,
            'shares': shares,
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # MAIN: scrape_page
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def scrape_page(self, account_cookies, page_url, progress_callback=None):
        """
        Luá»“ng:
          1. Load trang, cuá»™n Ä‘á»ƒ láº¥y háº¿t link bÃ i viáº¿t trong 24h
          2. Vá»›i má»—i link: click â†’ popup â†’ parse chi tiáº¿t
          3. Tráº£ vá» list[dict] Ä‘Ã£ sort theo tÆ°Æ¡ng tÃ¡c (likes + comments + shares)
        """
        results = []

        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=self.headless,
                args=['--disable-notifications', '--no-sandbox', '--disable-dev-shm-usage'],
            )
            context = browser.new_context(
                user_agent=(
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                    'AppleWebKit/537.36 (KHTML, like Gecko) '
                    'Chrome/122.0.0.0 Safari/537.36'
                ),
                viewport={'width': 1366, 'height': 900},
                locale='vi-VN',
            )
            self._load_cookies(context, account_cookies)
            page = context.new_page()

            try:
                logger.info(f"Navigating to {page_url}")
                page.goto(page_url, wait_until='domcontentloaded', timeout=30_000)
                time.sleep(4)

                # ÄÃ³ng popup login náº¿u cÃ³
                try:
                    page.keyboard.press('Escape')
                    time.sleep(0.5)
                except Exception:
                    pass

                # â”€â”€ BÆ¯á»šC 1: Thu tháº­p link â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                post_links = self._collect_post_links(page, progress_callback)
                logger.info(f"Found {len(post_links)} post links to process.")

                if progress_callback:
                    progress_callback(48)

                total = len(post_links)

                # â”€â”€ BÆ¯á»šC 2: Click tá»«ng link â†’ parse popup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                for idx, post_url in enumerate(post_links):
                    if progress_callback:
                        pct = 50 + int((idx / max(total, 1)) * 48)
                        progress_callback(pct)

                    logger.info(f"[{idx+1}/{total}] Opening {post_url}")
                    try:
                        # Äiá»u hÆ°á»›ng Ä‘áº¿n link bÃ i viáº¿t
                        page.goto(post_url, wait_until='domcontentloaded', timeout=20_000)
                        time.sleep(3)

                        post_data = self._parse_popup(page)
                        if not post_data:
                            logger.warning(f"Could not parse popup for {post_url}")
                            continue

                        post_data['post_url'] = post_url
                        results.append(post_data)

                        logger.info(
                            f"  âœ“ time={post_data.get('time_raw')} "
                            f"likes={post_data['likes']} "
                            f"comments={post_data['comments']} "
                            f"shares={post_data['shares']}"
                        )

                        # Quay láº¡i trang fanpage
                        page.go_back(wait_until='domcontentloaded', timeout=15_000)
                        time.sleep(2)

                    except PlaywrightTimeout:
                        logger.warning(f"Timeout on {post_url}, skipping.")
                        try:
                            page.go_back(wait_until='domcontentloaded', timeout=10_000)
                            time.sleep(1)
                        except Exception:
                            page.goto(page_url, wait_until='domcontentloaded', timeout=20_000)
                            time.sleep(3)
                        continue
                    except Exception as e:
                        logger.warning(f"Error on {post_url}: {e}")
                        try:
                            page.goto(page_url, wait_until='domcontentloaded', timeout=20_000)
                            time.sleep(2)
                        except Exception:
                            pass
                        continue

                # â”€â”€ BÆ¯á»šC 3: Sort by engagement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                results.sort(
                    key=lambda r: r['likes'] + r['comments'] * 2 + r['shares'] * 3,
                    reverse=True,
                )

                if progress_callback:
                    progress_callback(100)

                logger.info(
                    f"Done. {len(results)} posts collected and sorted by engagement."
                )
                return results

            except Exception as e:
                logger.error(f"Fatal error scraping {page_url}: {e}")
                return results
            finally:
                context.close()
                browser.close()
